{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f951495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI initialized successfully\n",
      "Processing PDF with 3 pages\n",
      "Page 1: Found 1 images\n",
      "Saved: page1_img1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated description for page1_image1: page1_image1 (RAG architecture diagram  \n",
      "workflow:  \n",
      "User Query -> Vector DB (Vectors) -> Context Re...\n",
      "Added image content for Image_1_Page_1\n",
      "Page 1 processed: 171 text elements, 0 tables, 1 images\n",
      "Page 2: Found 1 images\n",
      "Saved: page2_img1.png\n",
      "Generated description for page2_image1: page2_image1 (line chart: Popularity of RAG Over Time  \n",
      "year | popularity score  \n",
      "2020 | 10  \n",
      "2021 |...\n",
      "Added image content for Image_1_Page_2\n",
      "Page 2 processed: 24 text elements, 0 tables, 1 images\n",
      "Page 3: Found 0 images\n",
      "Page 3 processed: 79 text elements, 1 tables, 0 images\n",
      "Total documents created: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from pdfminer.high_level import extract_text\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "import base64\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "class HybridPDFLoader(BaseLoader):\n",
    "    \"\"\"Single-class PDF loader with smart library combination\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.azure_llm = None\n",
    "        \n",
    "        # Create extracted images folder\n",
    "        self.images_folder = os.path.join(os.path.dirname(file_path), \"extracted_images\")\n",
    "        os.makedirs(self.images_folder, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            self.azure_llm = AzureChatOpenAI(\n",
    "                deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "                api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "                azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "            )\n",
    "            print(\"Azure OpenAI initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Azure OpenAI setup failed: {e}\")\n",
    "\n",
    "    def _get_image_description(self, image_bytes: bytes, image_ext: str, page_number: int, img_index: int) -> str:\n",
    "        \"\"\"Generate AI description for image using Azure OpenAI\"\"\"\n",
    "        if not self.azure_llm or not image_bytes:\n",
    "            return \"Image extracted successfully.\"\n",
    "        \n",
    "        try:\n",
    "            # Convert image to base64\n",
    "            image_b64 = base64.b64encode(image_bytes).decode()\n",
    "\n",
    "            # Few-shot examples for guiding the model\n",
    "            examples = \"\"\"\n",
    "Example 1: page1_image1 (architecture of rag with sequential (parallel(input->chunking->embedding->vector store, user input->embedding), retrieval->LLM->output))\n",
    "\n",
    "Example 2: page2_image2 (profit per company bar chart\n",
    "company | profit\n",
    "company1 | 100 units\n",
    "company2 | 200 units\n",
    "\n",
    "red color represents company1\n",
    "blue color represents company2\n",
    "\n",
    "x-label = company name\n",
    "y-label = profit)\n",
    "\"\"\"\n",
    "\n",
    "            message = HumanMessage(content=[\n",
    "                {\"type\": \"text\", \"text\": f\"You are given an image extracted from a PDF. \"\n",
    "                                        f\"Write a short structured summary. \"\n",
    "                                        f\"If the image is a graph or chart, include axis labels, values, and colors. \"\n",
    "                                        f\"Follow the examples below:\\n\\n{examples}\\n\\n\"\n",
    "                                        f\"Now describe this image as page{page_number}_image{img_index} (...).\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{image_ext};base64,{image_b64}\"}}\n",
    "            ])\n",
    "\n",
    "            response = self.azure_llm.invoke([message])\n",
    "            description = response.content.strip()\n",
    "            print(f\"Generated description for page{page_number}_image{img_index}: {description[:100]}...\")\n",
    "            return description\n",
    "            \n",
    "        except Exception as llm_e:\n",
    "            print(f\"Azure OpenAI failed for image {img_index} on page {page_number}: {llm_e}\")\n",
    "            return \"Image extracted successfully.\"\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Single method that extracts text, tables, and images with smart library combination\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        try:\n",
    "            # Open with all three libraries simultaneously for efficiency\n",
    "            doc = fitz.open(self.file_path)  # PyMuPDF for images & page count\n",
    "            plumber_doc = pdfplumber.open(self.file_path)  # pdfplumber for tables & coordinates\n",
    "            \n",
    "            num_pages = len(doc)\n",
    "            print(f\"Processing PDF with {num_pages} pages\")\n",
    "            \n",
    "            for page_num in range(num_pages):\n",
    "                page_number = page_num + 1\n",
    "                content_parts = []\n",
    "                \n",
    "                # Initialize comprehensive metadata\n",
    "                metadata = {\n",
    "                    \"source\": self.file_path,\n",
    "                    \"page_number\": page_number,\n",
    "                    \"page_index\": page_num,\n",
    "                    \"total_pages\": num_pages,\n",
    "                    \"document_index\": page_num,\n",
    "                    \"elements\": {\n",
    "                        \"text\": [],\n",
    "                        \"tables\": [],\n",
    "                        \"images\": []\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                # TEXT LOADER - Use pdfminer.six + pdfplumber coordinates\n",
    "                try:\n",
    "                    # Get clean text from pdfminer\n",
    "                    text = extract_text(self.file_path, page_numbers=[page_num])\n",
    "                    if text and text.strip():\n",
    "                        content_parts.append(text.strip())\n",
    "                    \n",
    "                    # Get word coordinates from pdfplumber\n",
    "                    page = plumber_doc.pages[page_num]\n",
    "                    words = page.extract_words()\n",
    "                    \n",
    "                    # Add text metadata with indexing\n",
    "                    for i, word in enumerate(words):\n",
    "                        metadata[\"elements\"][\"text\"].append({\n",
    "                            \"index\": i,\n",
    "                            \"text\": word['text'],\n",
    "                            \"bbox\": (word['x0'], word['top'], word['x1'], word['bottom']),\n",
    "                            \"font\": word.get('fontname', 'Unknown'),\n",
    "                            \"size\": word.get('size', 0)\n",
    "                        })\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Text extraction error page {page_number}: {e}\")\n",
    "                \n",
    "                # TABLE LOADER - Use pdfplumber\n",
    "                try:\n",
    "                    page = plumber_doc.pages[page_num]\n",
    "                    tables = page.extract_tables()\n",
    "                    \n",
    "                    for i, table in enumerate(tables):\n",
    "                        if table:\n",
    "                            # Clean table data\n",
    "                            cleaned_table = [[str(cell) if cell is not None else \"\" for cell in row] for row in table]\n",
    "                            table_str = '\\n'.join([' | '.join(row) for row in cleaned_table])\n",
    "                            \n",
    "                            # Get table coordinates\n",
    "                            table_bbox = None\n",
    "                            try:\n",
    "                                found_tables = page.find_tables()\n",
    "                                if i < len(found_tables):\n",
    "                                    table_bbox = found_tables[i].bbox\n",
    "                            except:\n",
    "                                pass\n",
    "                            \n",
    "                            # Add to content and metadata\n",
    "                            content_parts.append(f\"\\n[Table {i+1}]\\n{table_str}\")\n",
    "                            metadata[\"elements\"][\"tables\"].append({\n",
    "                                \"index\": i,\n",
    "                                \"content\": cleaned_table,\n",
    "                                \"bbox\": table_bbox,\n",
    "                                \"rows\": len(cleaned_table),\n",
    "                                \"cols\": len(cleaned_table[0]) if cleaned_table else 0\n",
    "                            })\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Table extraction error page {page_number}: {e}\")\n",
    "                \n",
    "                # IMAGE LOADER - Use PyMuPDF with Azure OpenAI descriptions\n",
    "                try:\n",
    "                    page_obj = doc[page_num]\n",
    "                    images = page_obj.get_images(full=True)\n",
    "                    print(f\"Page {page_number}: Found {len(images)} images\")\n",
    "\n",
    "                    for img_index, img in enumerate(images, start=1):\n",
    "                        try:\n",
    "                            xref = img[0]  # image reference\n",
    "                            base_image = doc.extract_image(xref)\n",
    "                            image_bytes = base_image[\"image\"]\n",
    "                            image_ext = base_image[\"ext\"]\n",
    "\n",
    "                            # Get image coordinates\n",
    "                            img_rects = page_obj.get_image_rects(img)\n",
    "                            bbox = tuple(img_rects[0]) if img_rects else None\n",
    "\n",
    "                            # Build filename\n",
    "                            image_filename = f\"page{page_number}_img{img_index}.{image_ext}\"\n",
    "                            image_path = os.path.join(self.images_folder, image_filename)\n",
    "\n",
    "                            # Save image\n",
    "                            with open(image_path, \"wb\") as f:\n",
    "                                f.write(image_bytes)\n",
    "\n",
    "                            print(f\"Saved: {image_filename}\")\n",
    "\n",
    "                            # Generate AI image description using Azure OpenAI\n",
    "                            image_name = f\"Image_{img_index}_Page_{page_number}\"\n",
    "                            image_description = self._get_image_description(image_bytes, image_ext, page_number, img_index)\n",
    "                            \n",
    "                            # Add to content in the exact format you specified\n",
    "                            img_content = f\"\\n\\n[Image: {image_name}]\\nDescription: {image_description}\"\n",
    "                            content_parts.append(img_content)\n",
    "                            \n",
    "                            # Add to metadata\n",
    "                            metadata[\"elements\"][\"images\"].append({\n",
    "                                \"index\": img_index - 1,  # 0-based index for consistency\n",
    "                                \"name\": image_name,\n",
    "                                \"description\": image_description,\n",
    "                                \"bbox\": bbox,\n",
    "                                \"format\": image_ext,\n",
    "                                \"size_bytes\": len(image_bytes),\n",
    "                                \"saved_path\": image_path,\n",
    "                                \"filename\": image_filename,\n",
    "                                \"xref\": xref\n",
    "                            })\n",
    "\n",
    "                            print(f\"Added image content for {image_name}\")\n",
    "\n",
    "                        except Exception as img_e:\n",
    "                            print(f\"Image processing error {img_index} on page {page_number}: {img_e}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Image extraction error page {page_number}: {e}\")\n",
    "               \n",
    "                # Create final document with all content\n",
    "                combined_content = \"\\n\".join(content_parts).strip()\n",
    "                if combined_content:\n",
    "                    # Add summary counts to metadata\n",
    "                    metadata.update({\n",
    "                        \"text_count\": len(metadata[\"elements\"][\"text\"]),\n",
    "                        \"table_count\": len(metadata[\"elements\"][\"tables\"]), \n",
    "                        \"image_count\": len(metadata[\"elements\"][\"images\"]),\n",
    "                        \"total_elements\": sum([\n",
    "                            len(metadata[\"elements\"][\"text\"]),\n",
    "                            len(metadata[\"elements\"][\"tables\"]),\n",
    "                            len(metadata[\"elements\"][\"images\"])\n",
    "                        ])\n",
    "                    })\n",
    "                    \n",
    "                    documents.append(Document(\n",
    "                        page_content=combined_content,\n",
    "                        metadata=metadata\n",
    "                    ))\n",
    "                    \n",
    "                    print(f\"Page {page_number} processed: {metadata['text_count']} text elements, \"\n",
    "                          f\"{metadata['table_count']} tables, {metadata['image_count']} images\")\n",
    "            \n",
    "            # Cleanup\n",
    "            doc.close()\n",
    "            plumber_doc.close()\n",
    "            \n",
    "            print(f\"Total documents created: {len(documents)}\")\n",
    "            return documents\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"PDF processing error: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "\n",
    "loader = HybridPDFLoader(r\"C:\\Users\\bluea\\OneDrive\\Desktop\\MMRAG\\PDF\\Test.pdf\")\n",
    "docs = loader.load()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
